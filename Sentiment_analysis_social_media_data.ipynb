{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46fcc342",
   "metadata": {},
   "source": [
    "## Pre-processing textural data from social media"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26969258",
   "metadata": {},
   "source": [
    "Our objective is to:\n",
    "\n",
    "- identify positive and negative sentiments related to cheesecake\n",
    "- use the polarity score function and identify related words\n",
    "- visualise the output to present back to the business to help them decide on adding a flavour to their product line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ec3ed0",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "##  Prepare your workstation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d529667",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:/Jupyter Notebook/LSE_DA_03_Python/C3 Week 3/twitter.yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/l7/2mtcb_kx4x7fv5g8kfqjrf1m0000gn/T/ipykernel_10515/3120730861.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Import the yaml file - remember to specify the whole path and use / between directories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtwitter_creds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msafe_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'D:/Jupyter Notebook/LSE_DA_03_Python/C3 Week 3/twitter.yaml'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:/Jupyter Notebook/LSE_DA_03_Python/C3 Week 3/twitter.yaml'"
     ]
    }
   ],
   "source": [
    "# Copy the YAML file and your Twitter keys over to this Jupyter Notebook before you start to work\n",
    "import yaml\n",
    "from yaml.loader import SafeLoader\n",
    "from twitter import *\n",
    "\n",
    "# Import the yaml file - remember to specify the whole path and use / between directories\n",
    "twitter_creds = yaml.safe_load(open('D:/Jupyter Notebook/LSE_DA_03_Python/C3 Week 3/twitter.yaml', 'r').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f554d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass your twitter credentials\n",
    "twitter_api = Twitter(auth=OAuth(twitter_creds['access_token'],\n",
    "                                 twitter_creds['access_token_secret'], \n",
    "                                 twitter_creds['api_key'],\n",
    "                                 twitter_creds['api_secret_key'] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b72765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See if you are connected\n",
    "print(twitter_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b0148f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a test with #python\n",
    "python_tweets = twitter_api.search.tweets(q=\"#python\")\n",
    "\n",
    "# View output\n",
    "print(python_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a657692",
   "metadata": {},
   "source": [
    "## 1. Test connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f249f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the term cheesecake\n",
    "q = {'q':'cheesecake', 'count':100, 'result_type':'recent'}\n",
    "results = []\n",
    "\n",
    "while len(results) < 30:\n",
    "    query = twitter_api.search.tweets(**q)\n",
    "    q['max_id'] = query['search_metadata']['next_results'].split('&')[0].split('?max_id=')[1]\n",
    "    results.append(query)\n",
    "    \n",
    "# Determine the number of results\n",
    "len(results)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb192e4",
   "metadata": {},
   "source": [
    "## 2. Create DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec148ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas to join the DataFrames\n",
    "import pandas as pd\n",
    "\n",
    "# Concat DataFrames\n",
    "results_list_pd = pd.concat([pd.DataFrame(_['statuses']) for _ in results])\n",
    "\n",
    "# View shape of output\n",
    "results_list_pd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69e4f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine values of output\n",
    "results_list_values = results_list_pd['text'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5946755e",
   "metadata": {},
   "source": [
    "## 3. Investigate tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51943af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import nltk and the required resources\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import words\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8684a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at one raw tweet\n",
    "results_list_values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf683cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split up each tweet into individual words\n",
    "results_list_values_token = [word_tokenize(_) for _ in results_list_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fec69a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all english words so we can exclude anything that doesnt appear on the list\n",
    "all_english_words = set(words.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdfb97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some pre-processing:\n",
    "#-- lets get every word\n",
    "#-- lets convert it to lowercase\n",
    "#-- only include if the word is alphanumeric and if it is in the list of English words.\n",
    "\n",
    "results_list_values_token_nostop =\\\n",
    "[[y.lower() for y in x if y.lower() not in stop_words and y.isalpha() and y.lower() in all_english_words]\\\n",
    " for x in results_list_values_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ba3c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's have a look at the same tweet as above\n",
    "results_list_values_token_nostop[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff7fbce",
   "metadata": {},
   "source": [
    "# NLTK sentiment analysis \n",
    "## 1. Import NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc35f40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the prebuilt rules and values of the vader lexicon\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c985ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the vader classs and create a object of the analyzer called Darth Vader\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Create a variable to store the sia\n",
    "darth_vader = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47326f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run through a dictionary comprehension to take every cleaned tweet \n",
    "# Next run the polarity score function on the string.\n",
    "# This will return four values in a dictionary\n",
    "\n",
    "results_list_values_token_nostop_polarity =\\\n",
    "{\" \".join(_) : darth_vader.polarity_scores(\" \".join(_)) for _ in results_list_values_token_nostop}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693ed7b5",
   "metadata": {},
   "source": [
    "## 2. Create a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58c97f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of dictionary results to a pandas dataframe. \n",
    "# The index is the cleaned tweet.\n",
    "# We can see some of the highly positive words \n",
    "\n",
    "polarity_pd = pd.DataFrame(results_list_values_token_nostop_polarity).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3059cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the non-aplhanumeric words (the emojis, handles, hashtags and stopwords) removed \n",
    "# some of the most positive words are single words\n",
    "\n",
    "# Get the top 5 most positive cleaned tweets related to cheesecake\n",
    "polarity_pd.sort_values('pos', ascending=0).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde71e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 5 most negative words related to cheesecake\n",
    "polarity_pd.sort_values('neg', ascending=0).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95114767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The describe function on the compound will show the distribution and moments. \n",
    "# The average is 0.1 so slightly positive\n",
    "polarity_pd['compound'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0152065b",
   "metadata": {},
   "source": [
    "## 3. Plot the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e133b662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometimes the best way to see is to plot. \n",
    "# In the data sampled here many of the values are 0\n",
    "# There are less negative values than positive but the negative values are highly negative.\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_plot = polarity_pd.reset_index()['compound'].sort_values()\n",
    "_plot.plot(kind='bar')\n",
    "ax1 = plt.axes()\n",
    "x_axis = ax1.axes.get_xaxis()\n",
    "x_axis.set_visible(False)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e85e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The boxplot is a nice way to see how many values sit on the edges as outliers.\n",
    "_plot = polarity_pd.reset_index()['compound'].sort_values()\n",
    "_plot.plot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40345496",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
